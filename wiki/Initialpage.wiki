https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/logo3.png

= Social Robotics using NAO and Kinect =

== Robotics Project - Interaction Lab - Heriot-Watt University ==

https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/logo2.png

== Members == 

== Contents ==

 # [#Introduction Introduction]
 # [#Problem_Statement Problem Statement]
 # [#Method Method]
  * [Preprocessing]
  * [Matchingdistance 2D Chamfer Matching Distance]
  * [HeadParameters Head Parameters Estimation]
  * [Segmentation]
  * [Tracking]
 # [#Implementation Implementation]
  * [SoftwareArchitecture Software Architecture]
 # [#Demo Demo]
 # [#Conclusions Conclusions]
 # [References References]
 # [#Links_of_Interest Links of Interest]

== Introduction ==

As robots become involved into daily life, they must need to deal under situations in which social interaction is essential. It implies robot must be able to satisfy the social goals and obligations that come up through interactions with people in real-world settings, which demand challenges on reasoning, decision making and action selection components of the system. [References 1]

A social robot is defined as "an autonomous robot that interacts and communicates with humans or other autonomous physical agents by following social behaviours and rules attached to its role" Additionally, social robots need to understand and react intelligently to the actions and intentions of multiple humans in a visual scene.

https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/socialrobots.png

This project combines a NAO torso with a Kinect controller in order to estimate the social scene in a bar/pub/caf√© style interaction with multiple users. The main work in the project will be in vision by using the Kinect to detect multiple humans and perform face tracking and gaze estimation. A particular focus will be on detecting when humans want attention from the robot.

== Problem Statement ==

Humans use head pose and gaze direction as nonverbal cues to express communicative acts and their visual focus of attention. Additionally, head direction and pointing gestures can contribute significantly to the computation of the attention of an interaction partner. 

Hence, a combination of head pose estimation and recognition of gaze directions is needed to exactly determine the visual attention of an interaction partner.  Gaschler et al. show in [References 2] that head pose is an important cue that is used by customers and bartenders in all steps of the ordering sequence. 

Humans can easily estimate the head pose of an interaction partner, but for a computer vision system this ability is rather difficult to achieve. The pose is described by the approximate position of the head in space, and an angle that describes torso orientation.

Many methods have been used to generate a head pose estimation. Appearance-based methods consider the image region of the face as a whole, while Feature-based methods extract from the actual region and recover low-dimensional features (position of facial features). Both techniques can be combined in order to track facial features.

== Method ==
 * [Preprocessing]
 * [Matchingdistance 2D Chamfer Matching Distance]
 * [HeadParameters Head Parameters Estimation]
 * [Segmentation]
 * [Tracking]
== Demo ==
== Implementation ==
 * [SoftwareArchitecture Software Architecture]
== Conclusions ==


== Links of Interest == 
*Presentations*
 # [http://prezi.com/e-5801a4gmsm/rp-presentation-1/ Presentation 1 -  October 17th, 2012]
 # [http://prezi.com/qvdukdcb9ikg/rp-presentation-2/ Presentation 2 -  October 30th, 2012]

*Dataset and Demo for Human Detections*
 # [http://www.informatik.uni-freiburg.de/~spinello/RGBD-dataset.html RGB-D People Dataset]
 # [http://www.youtube.com/watch?feature=player_embedded&v=UwHOGfXxajM People Detection in RGB-D Data]

*Projects and Group Research*
 # [http://www.james-project.eu EU project JAMES]
 # [https://sites.google.com/site/hwinteractionlab/home Interaction Lab - Heriot-Watt University]
 # [http://web.media.mit.edu/~cynthiab/research/research.html Personal Robots Group - Massachusetts Institute of Technology]

*Social Robot Demos*
 # [http://www.youtube.com/watch?v=8k7Pd-CbbhE&feature=youtu.be JAMES, the robot bartender, system evaluation April / May 2012]
 # [http://www.youtube.com/watch?v=ilmDN2e_Flc&feature=related Leonardo Robot - isn't this the cutest robot ever?]
 # [http://www.youtube.com/watch?v=aQS2zxmrrrA Official MDS Robot Video - First Test of Expressive Ability]