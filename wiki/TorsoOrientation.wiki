https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/logo3.png


= Torso Orientation =

== Introduction==

The pose estimation of the head can be estimated from pixel location in the image by using the extrinsic and intrinsic parameters of the camera calibration. However, the angle that describes torso orientation can be a challenging problem, if a 3D model is not available.
One of the advantages of kinect, is the generation of range images that provide 3D information. In this site, we will explain how to use this information to compute the angle of torso orientation by using a very straighforward algorithm.

== Algorithm ==
This algorithm is carried out by using the depth image generated by Kinect. However, a disparity image is used in order to illustrate every step of this procedure.

===Step 1:  ===
The inputs of this algorithm is the 2D coordinates of the centroid (x,y) generated by the face detection (see the below right-hand side picture )

https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step1.png

===Step 2:  === 
Starting from the centroids, we look for the maximum variation of pixel intensity values, which represent the depth of the image. We take the vertical direction in order to reach the superior part of the head. A significant variation is assumed to be located at the border between the human and the background, specifically, to a 'x' distance from the detected centroid. Hence, we can stablish clearly the top boundary. The following figure illustrates this step for two detected persons.

https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step2.png

===Step 3:  ===
Based on propotion estimates, we look for a point in the torso region that allows to have a better estimation of the orientation. For that reason, we move a 1.5x distance from the centroid in the opposite direction (see green lines on the below figure)

https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step3.png
===Step 4:  === 
Once the torso region has been reached, we proceed to find the side boundaries. Since we know the size of the image, we stablish as reference the middle part of it.

*1* If the person is located to the left-hand side of the middle part of the image, we look for the right side boundary of the person.

*2* Otherwise, we look for the left side boundary of the person.
The idea of this method is to avoid the borders of the image.

https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step4.png

===Step 6:  === 
https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step6.png
===Step 7:  === 
https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step7.png
===Step 8:  === 
https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step8.png
===Step 9:  ===
https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step9.png
===Step 10: ===
https://scoialrobot.googlecode.com/svn/trunk/social_robot/pictures/step10.png
== Limitations ==